---
title: "CulturalBechdel-Final"
author: "Anna Schaap Kristensen (ASK), Matilda Rhys-Kristensen (MRK), Josephine Kianna Pallisgaard SÃ¸rensen (JKS)"
date: "2024-11-19"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, JKS}
# install packages
install.packages("pacman")
install.packages("reshape2")
install.packages('brant')
install.packages('ggeffects')
pacman::p_load(tidyverse, readr, ggplot2, dplyr, tidyr, car, MASS, brant, ggeffects)

```
## Loading data
```{r, JKS}
## Load data
bechdel2_df <- read_csv("../data/Bechdel_IMDB_Merge0524.csv")

## subsetting to include only the same period of time before and after 2017 (MeToo)
df_subset <- bechdel2_df %>% filter(year >=2011)
```
# Exporing our Data
```{r, JKS}
# Plotting number of films for each release year, see every 5 years on x-axis for each data set
df_subset %>%
  count(year) %>%
  ggplot(aes(x = year, y = n)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(title = "Number of films for each release year",
       x = "Release Year",
       y = "Count") +
  scale_x_continuous(breaks = seq(1900, 2020, by = 5))

```

```{r, MRK}
# Making table with no. of films with each rating value of 0-3
df_subset %>% 
  group_by(bechdelRating) %>% 
  summarise(count = n()) %>% 
  ggplot(aes(x = bechdelRating, y = count)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(title = "Number of films with each rating value",
       x = "Rating",
       y = "Count")
```
```{r, MRK}
# plot all genres
df_subset %>%
  gather(key = "genre_column", value = "genre_value", genre1:genre3) %>%  # Gather all genre columns
  filter(!is.na(genre_value)) %>%  # Remove rows where genre is NA
  count(genre_value, name = "Count") %>%  # Count occurrences of each genre
  ggplot(aes(x = reorder(genre_value, -Count), y = Count)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(title = "Number of films in each genre category",
       x = "Genre",
       y = "Count") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# plot only first genre
df_subset %>%
  count(genre1) %>%
  ggplot(aes(x = genre1, y = n)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(title = "Number of films in each genre category",
       x = "Genre",
       y = "Count") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# facetwrap by Bechdel rating
df_subset %>%
  gather(key = "genre_column", value = "genre_value", genre1:genre3) %>%  # Gather all genre columns
  filter(!is.na(genre_value)) %>%  # Remove rows where genre is NA
  count(bechdelRating, genre_value, name = "Count") %>%  # Count occurrences of each genre
  ggplot(aes(x = reorder(genre_value, -Count), y = Count)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(title = "Number of films in each genre category",
       x = "Genre",
       y = "Count") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  facet_wrap(~ bechdelRating ,ncol=1)  # Facet by Rating

```
```{r data cleaning, ASK}
# adding a before or after 2017 column (binary variable) 
df_subset$after2017 <- ifelse(df_subset$year > 2017, 1, 0)

# Reshape and one-hot encode genres (in order to include all genres in the model)
data_long <- df_subset %>%
  pivot_longer(cols = starts_with("genre"), names_to = "genre_type", values_to = "genre") %>% 
  dplyr::select(-genre_type)  # Remove unnecessary column

data_long <- reshape2::melt(df_subset, id.vars = c("title", "bechdelRating", "year", "after2017"), 
                  measure.vars = c("genre1", "genre2", "genre3"),
                  variable.name = "genre_type", value.name = "genre")

data_wide <- reshape2::dcast(data_long, title + bechdelRating + year + after2017 ~ genre, 
                      fun.aggregate = length, value.var = "genre")

# removing NA and backslash N column and News (only one movie has this genre)
data_wide <- data_wide %>% 
  dplyr::select(-c('NA', 5, 'News'))

# doing the same for data long (used for plotting)
data_long <- data_long %>% 
  filter(genre != "NA" & genre != "News")

data_long <- data_long[-1304, ] # because i could not remove the backslash N value in other ways

# renaming SciFi column
data_wide$SciFi <- data_wide$`Sci-Fi`

# doing the same for data long
data_long$genre <- gsub("-", "", data_long$genre)

```

Ordinal logistic regression
```{r Hypothesis 1, JSK}
# convert to factors
data_wide$bechdelRating <- as.factor(data_wide$bechdelRating)
data_wide$after2017 <- as.factor(data_wide$after2017)

# Model: ordnial logistic regression
model5 <- polr(bechdelRating ~ after2017, data = data_wide)
summary(model5)

```
```{r calculating p-values and CI, MRK}
# Calculate P-values
model_summary <- summary(model5)

# Extract the coefficients, standard errors, and t-values
coefficients <- model_summary$coef[, "Value"]
standard_errors <- model_summary$coef[, "Std. Error"]
t_values <- model_summary$coef[, "t value"]

# Calculate p-values using the normal approximation
p_values <- 2 * pnorm(abs(t_values), lower.tail = FALSE)

# Calculate confidence intervals (95%)
lower_bound <- coefficients - 1.96 * standard_errors
upper_bound <- coefficients + 1.96 * standard_errors

# Output the coefficients and p-values for easy interpretation
results_df <- data.frame(
  Variable = rownames(results_df),
  Coefficients = coefficients,
  StandardErrors = standard_errors,
  tValues = t_values,
  pValues = p_values,
  ci_lower = lower_bound,
  ci_upper = upper_bound
)

# Print the results
print(results_df)

```

```{r testing for the proportional odds assumption, ASK}
# Perform the Brant test: this is a test for the proportional odds assumption (which is that the relationship between the predictors and the log-odds of the response variable is constant across all thresholds)
brant_test <- brant(model5)

# Print the results: if p-value is HIGHER than 0.05, then we are good. 
print(brant_test)
```
```{r, JSK}
# Plot the results using ggplot2
ggplot(results_df, aes(x = Coefficients, y = Variable, color = Variable)) +
  geom_point(size = 3) +  # Plot the coefficients
  geom_errorbarh(aes(xmin = ci_lower, xmax = ci_upper), height = 0.2) +  # Add error bars
  geom_vline(xintercept = 0, linetype = "dashed", color = "red") +  # Add reference line at 0
  labs(
    title = "Hypothesis 1: Coefficient Estimates with 95% Confidence Intervals",
    x = "Estimate",
    y = "Coefficient"
  ) +
  theme_minimal() +
  theme(
    axis.text.y = element_text(size = 12),
    axis.title = element_text(size = 14)
  ) +
  theme_minimal()

```
```{r calculating probabilities for plot, MRK}
# Predicted probabilities
predicted_probs <- predict(model5, type = "probs")
predicted_probs <- as.data.frame(predicted_probs) # make df
colnames(predicted_probs) <- levels(data_wide$bechdelRating) # Add column names to match category labels
 
# Add predictions to the original data
data_with_probs <- cbind(data_wide, predicted_probs)

# Reshape the dataset into long format
data_long_2 <- data_with_probs %>%
  pivot_longer(
    cols = all_of(levels(data_wide$bechdelRating)), # Columns for categories
    names_to = "bechdelCategory",                  # New column for category labels
    values_to = "probability"                      # New column for probabilities
  )

data_long_2a <- data_long_2 %>%
  pivot_longer(
    cols = 5:26,  
    names_to = "genre",                   
    values_to = "yn" # random name just to store whether a film has a genre or not which is used to filter out films without that genre un the next lines
  )

data_long_2a <- data_long_2a %>%
  filter(yn == 1) %>%
  dplyr::select(-yn)
```


```{r, ASK}
ggplot(data_long_2a, aes(x = as.numeric(as.factor(after2017)), y = probability, color = bechdelCategory)) +
  geom_line(aes(group = bechdelCategory)) +
  geom_point() +
  scale_x_continuous(breaks = c(1, 2), labels = c("Before 2017", "After 2017")) +
  labs(
    title = "Predicted Probabilities of Bechdel Ratings",
    x = "Before and After 2017",
    y = "Probability",
    color = "Bechdel Rating"
  ) +
  theme_minimal()


```
Ordinal Logistic Regression with all genres

```{r Hypothesis 2: interaction genre model, JSK}
# making two different to see which is best multicolinarity wise (chunk underneath)
model2 <- polr(bechdelRating ~ after2017 * (Action + Adventure + Animation + Biography + Comedy + Crime + Documentary + Drama + Family + Fantasy + History + Horror + Music + Musical + Mystery + Romance + SciFi + Sport + Thriller + War + Western), data = data_wide)

model3 <- polr(bechdelRating ~after2017 : (Action + Adventure + Animation + Biography + Comedy + Crime + Documentary + Drama + Family + Fantasy + History + Horror + Music + Musical + Mystery + Romance + SciFi + Sport + Thriller + War + Western), 
               data = data_wide)

```

```{r checking for multicolinearity between predictors, MRK}
vif(model2)
vif(model3)

# model 2 has too much multicolinearity (after2017 especially), model3 looks good tho, lets check that output:
summary(model3)

```
```{r testing for the proportional odds assumption, ASK}
# Perform the Brant test: this is a test for the proportional odds assumption (which is that the relationship between the predictors and the log-odds of the response variable is constant across all thresholds)
brant_test <- brant(model3)

# Print the results: if p-value is HIGHER than 0.05, then we are good. 
print(brant_test)

# massive violation for many predictors. probably because likelihood for genres changes across intercepts (not linear). Important to comment on!!
```
```{r extracting model outputs and computing CIs from model summary, JSK}
# 1. Get the summary of the model 3
model3_summary <- summary(model3)

# 2. Extract the coefficients, standard errors, t-values, and p-values for the model
coefficients_model3 <- model3_summary$coef[, "Value"]
standard_errors_model3 <- model3_summary$coef[, "Std. Error"]
t_values_model3 <- model3_summary$coef[, "t value"]

# Calculate confidence intervals (95%)
lower_bound <- coefficients_model3 - 1.96 * standard_errors_model3
upper_bound <- coefficients_model3 + 1.96 * standard_errors_model3

# 3. Create a data frame with coefficients, standard errors, t-values, and p-values
coefficients_df <- data.frame(
  Variable = rownames(model3_summary$coef),
  Coefficients = coefficients_model3,
  StandardErrors = standard_errors_model3,
  tValues = t_values_model3,
  ci_lower = lower_bound,
  ci_upper = upper_bound
)

```
```{r formatting data for plotting, MRK}
# Extract coefficients and standard errors respectively for 2017 and before and for after 2017
genre <- sub(".*:(.*)", "\\1", rownames(coefficients_df)[grepl("20170", rownames(coefficients_df))])
coeff_20170 <- coefficients_df[grepl("20170", rownames(coefficients_df)), "Coefficients"]
coeff_20171 <- coefficients_df[grepl("20171", rownames(coefficients_df)), "Coefficients"]
se_20170 <- coefficients_df[grepl("20170", rownames(coefficients_df)), "StandardErrors"]
se_20171 <- coefficients_df[grepl("20171", rownames(coefficients_df)), "StandardErrors"]

# difference between the coefficients as we are interested in whether there is a significant change in bechdelRatings for each genre
coefficient_diff <- coeff_20171 - coeff_20170

# standard error of the difference
se_diff <- sqrt(se_20170^2 + se_20171^2)

# the 95% confidence intervals for the difference
lower_ci <- coefficient_diff - 1.96 * se_diff
upper_ci <- coefficient_diff + 1.96 * se_diff

# combining results in one data frame
diff_df <- data.frame(
  genre = genre,
  coefficient_diff = coefficient_diff,
  lower_ci = lower_ci,
  upper_ci = upper_ci
)

# Visualize the difference and confidence intervals
ggplot(diff_df, aes(x = genre, y = coefficient_diff, color = genre)) +
  geom_point() +
  geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci)) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  theme_minimal() +
  labs(
    title = "Change in Bechdel Rating for each Genre",
    x = "Genre",
    y = "Change in Bechdel Rating (2017 and before vs after 2017",
  ) +
  coord_flip() +
  theme(legend.position = "none") +
  guides(color = FALSE) +
  theme_minimal()

```

```{r calculate probabilities for plots, ASK}

# Generate predicted probabilities for all categories of 'bechdelRating'
predicted_probs_model3 <- predict(model3, type = "probs")

# Convert predicted probabilities to a data frame
predicted_probs_df3 <- as.data.frame(predicted_probs_model3)

# Assign the correct column names based on the levels of 'bechdelRating'
colnames(predicted_probs_df3) <- levels(data_wide$bechdelRating)

# 2. Add predicted probabilities to the original dataset (without overwriting)
data_with_probs_model3 <- cbind(data_wide, predicted_probs_df3)

# turning into long format again in order to be able to plot
data_long_model3 <- data_with_probs_model3 %>%
  pivot_longer(
    cols = all_of(levels(data_wide$bechdelRating)), 
    names_to = "bechdelCategory",                   
    values_to = "probability"                        
  )

data_long_model3 <- data_long_model3 %>%
  pivot_longer(
    cols = 5:26,  
    names_to = "genre",                   
    values_to = "yn" # random name just to store whether a film has a genre or not which is used to filter out films without that genre un the next lines
  )

data_longer_model3 <- data_long_model3 %>%
  filter(yn == 1) %>%
  dplyr::select(-yn)
 
```

# Plot
```{r PLOT genres, JSK}
# based on significant genres, marked by preceding plot, we will specifically plot them:
data_long_model3_s <- data_longer_model3 %>%
  filter(genre %in% c("Action", "Comedy"))

ggplot(data_long_model3_s, aes(x = as.numeric(as.factor(after2017)), y = bechdelRating, group = genre, color = genre)) +
  geom_smooth(method = "lm") +
  scale_x_continuous(breaks = c(1, 2), labels = c("Before 2017", "After 2017")) +
  labs(title = "Bechdel rating over time for Significant Genres",
       x = "Year",
       y = "Bechdel rating") +
  theme_minimal()
```


